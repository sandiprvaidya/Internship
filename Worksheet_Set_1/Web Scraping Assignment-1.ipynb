{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0be5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13d2fbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "              Header\n",
      "0          Main page\n",
      "1           Contents\n",
      "2     Current events\n",
      "3     Random article\n",
      "4    About Wikipedia\n",
      "..               ...\n",
      "96               ไทย\n",
      "97            Türkçe\n",
      "98        Українська\n",
      "99        Tiếng Việt\n",
      "100               中文\n",
      "\n",
      "[101 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Write a python program to display all the header tags from wikipedia.org and make data frame.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "header = []\n",
    "for i in  soup.find_all('li',class_=\"mw-list-item\"):\n",
    "    header.append(i.text)\n",
    "    \n",
    "print(len(header)) \n",
    "df = pd.DataFrame({\"Header\":header})\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5182edd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Names]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "names = []\n",
    "for i in  soup.find_all('div',class_=\"desc-sec\"):\n",
    "    names.append(i.text)    \n",
    "print(len(names))\n",
    "\n",
    "df = pd.DataFrame({'Names':names})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c81df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Teams, Matches, Points, Ratings]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "teams = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-team\"):\n",
    "    teams.append(i.text.)\n",
    "    \n",
    "    \n",
    "matches = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-matches\"):\n",
    "    matches.append(i.text.)\n",
    "    \n",
    "points = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-pts\"):\n",
    "    points.append(i.text.)\n",
    "    \n",
    "ratings = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-rating\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "print(len(teams),len(matches),len(points),len(ratings)) \n",
    "\n",
    "df = pd.DataFrame({'Teams':teams[:10],'Matches':matches[:10],'Points':points[:10],'Ratings':ratings[:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91942ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Players</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Players, Team, Ratings]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "players = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-player\"):\n",
    "    players.append(i.text)\n",
    "    \n",
    "    \n",
    "team = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-team\"):\n",
    "    team.append(i.text)\n",
    "    \n",
    "ratings = []\n",
    "for i in  soup.find_all('span',clas_s=\"si-text\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "print(len(players),len(team),len(ratings)) \n",
    "\n",
    "df = pd.DataFrame({'Players':players,'Team':team,'Ratings':ratings})\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6984ce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowler</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Bowler, Team, Ratings]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 ODI bowlers along with the records of their team andrating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "bowler = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-player\"):\n",
    "    bowler.append(i.text)\n",
    "    \n",
    "    \n",
    "team = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-team\"):\n",
    "    team.append(i.text)\n",
    "    \n",
    "ratings = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-rating\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "\n",
    "print(len(players),len(team),len(ratings)) \n",
    "\n",
    "df = pd.DataFrame({'Bowler':bowler,'Team':team,'Ratings':ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03036ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Teams, Matches, Points, Ratings]\n",
       "Index: []"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/team-rankings/womens/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "teams = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-team\"):\n",
    "    teams.append(i.text)\n",
    "    \n",
    "    \n",
    "matches = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-matches\"):\n",
    "    matches.append(i.text)\n",
    "    \n",
    "points = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-pts\"):\n",
    "    points.append(i.text)\n",
    "    \n",
    "ratings = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-rating\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "print(len(teams),len(matches),len(points),len(ratings)) \n",
    "\n",
    "df = pd.DataFrame({'Teams':teams[:10],'Matches':matches[:10],'Points':points[:10],'Ratings':ratings[:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d45343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Players</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Players, Team, Ratings]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/team-rankings/womens/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "players = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-player\"):\n",
    "    players.append(i.text)\n",
    "    \n",
    "    \n",
    "team = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-team\"):\n",
    "    team.append(i.text)\n",
    "    \n",
    "ratings = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-rating\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "\n",
    "print(len(players),len(team),len(ratings)) \n",
    "\n",
    "df = pd.DataFrame({'Players':players,'Team':team,'Ratings':ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe40059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Player, Team, Ratings]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/team-rankings/womens/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "player = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-player\"):\n",
    "    player.append(i.text)\n",
    "    \n",
    "    \n",
    "team = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-team\"):\n",
    "    team.append(i.text)\n",
    "    \n",
    "ratings = []\n",
    "for i in  soup.find_all('div',class_=\"si-table-data si-rating\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "\n",
    "print(len(players),len(team),len(ratings)) \n",
    "\n",
    "df = pd.DataFrame({'Player':player,'Team':team,'Ratings':ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbb33490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16 Hours AgoWall Street touted 5 portfolio sto...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17 Hours AgoBeijing intensifies military press...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18 Hours AgoHow the Apple iPhone became one of...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19 Hours AgoMark Ruffalo 'couldn't afford a ca...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 Hours Ago10 of our stocks report earnings n...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20 Hours AgoFlorida is the No. 1 state to reti...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21 Hours AgoThe future of American amusement p...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21 Hours Ago2 surprising reasons why skipping ...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21 Hours Ago28-year-old worth more than $500,0...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21 Hours AgoGen Z vs. their parents: How the g...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22 Hours AgoHow Guyana's big oil boom turned i...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22 Hours AgoWhy kids TV content is vital to st...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22 Hours AgoThese energy stocks may rally afte...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22 Hours AgoBuy these top tech stocks into ear...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22 Hours AgoQuality stocks are dominating the ...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23 Hours AgoA handful of space companies are r...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>January 26, 2024WWE founder Vince McMahon resi...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>January 26, 2024Why weakness in small caps may...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>January 26, 2024Cramer's Lightning Round: Cons...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>January 26, 2024Rivian CEO says EV market suff...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>January 26, 2024Cramer's week ahead: Fed meeti...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>January 26, 2024Oil tanker hit by missile in G...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>January 26, 2024FTC fines Kubota $2 million in...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>January 26, 2024Merck, J&amp;J CEOs agree to testi...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>January 26, 2024Former New York Gov. Andrew Cu...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>January 26, 2024Shut out of the high-flying Su...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>January 26, 2024Why Jim Cramer says it might b...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>January 26, 2024Wall Street barreling toward b...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>January 26, 2024A slate of banks slashed CD yi...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>January 26, 2024BrightSpring debut is the late...</td>\n",
       "      <td>January 26, 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headlines              Time\n",
       "0   16 Hours AgoWall Street touted 5 portfolio sto...      16 Hours Ago\n",
       "1   17 Hours AgoBeijing intensifies military press...      17 Hours Ago\n",
       "2   18 Hours AgoHow the Apple iPhone became one of...      18 Hours Ago\n",
       "3   19 Hours AgoMark Ruffalo 'couldn't afford a ca...      19 Hours Ago\n",
       "4   20 Hours Ago10 of our stocks report earnings n...      20 Hours Ago\n",
       "5   20 Hours AgoFlorida is the No. 1 state to reti...      20 Hours Ago\n",
       "6   21 Hours AgoThe future of American amusement p...      21 Hours Ago\n",
       "7   21 Hours Ago2 surprising reasons why skipping ...      21 Hours Ago\n",
       "8   21 Hours Ago28-year-old worth more than $500,0...      21 Hours Ago\n",
       "9   21 Hours AgoGen Z vs. their parents: How the g...      21 Hours Ago\n",
       "10  22 Hours AgoHow Guyana's big oil boom turned i...      22 Hours Ago\n",
       "11  22 Hours AgoWhy kids TV content is vital to st...      22 Hours Ago\n",
       "12  22 Hours AgoThese energy stocks may rally afte...      22 Hours Ago\n",
       "13  22 Hours AgoBuy these top tech stocks into ear...      22 Hours Ago\n",
       "14  22 Hours AgoQuality stocks are dominating the ...      22 Hours Ago\n",
       "15  23 Hours AgoA handful of space companies are r...      23 Hours Ago\n",
       "16  January 26, 2024WWE founder Vince McMahon resi...  January 26, 2024\n",
       "17  January 26, 2024Why weakness in small caps may...  January 26, 2024\n",
       "18  January 26, 2024Cramer's Lightning Round: Cons...  January 26, 2024\n",
       "19  January 26, 2024Rivian CEO says EV market suff...  January 26, 2024\n",
       "20  January 26, 2024Cramer's week ahead: Fed meeti...  January 26, 2024\n",
       "21  January 26, 2024Oil tanker hit by missile in G...  January 26, 2024\n",
       "22  January 26, 2024FTC fines Kubota $2 million in...  January 26, 2024\n",
       "23  January 26, 2024Merck, J&J CEOs agree to testi...  January 26, 2024\n",
       "24  January 26, 2024Former New York Gov. Andrew Cu...  January 26, 2024\n",
       "25  January 26, 2024Shut out of the high-flying Su...  January 26, 2024\n",
       "26  January 26, 2024Why Jim Cramer says it might b...  January 26, 2024\n",
       "27  January 26, 2024Wall Street barreling toward b...  January 26, 2024\n",
       "28  January 26, 2024A slate of banks slashed CD yi...  January 26, 2024\n",
       "29  January 26, 2024BrightSpring debut is the late...  January 26, 2024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
    "make data frame\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "headlines = []\n",
    "for i in  soup.find_all('div',class_=\"LatestNews-headlineWrapper\"):\n",
    "    headlines.append(i.text)\n",
    "    \n",
    "    \n",
    "time = []\n",
    "for i in  soup.find_all('span',class_=\"LatestNews-wrapper\"):\n",
    "    time.append(i.text)\n",
    "    \n",
    "print(len(headlines),len(time)) \n",
    "df = pd.DataFrame({'Headlines':headlines,'Time':time})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5431a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24 24 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>Reward is enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...   \n",
       "7   Explaining individual predictions when feature...   \n",
       "8       Multiple object tracking: A literature review   \n",
       "9   A survey of inverse reinforcement learning: Ch...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Explainable AI tools for legal reasoning about...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  Assessing the communication gap between AI mod...   \n",
       "14  Explaining black-box classifiers using post-ho...   \n",
       "15  The Hanabi challenge: A new frontier for AI re...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17  Artificial cognition for social human–robot in...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  The multifaceted impact of Ada Lovelace in the...   \n",
       "20  Robot ethics: Mapping the issues for a mechani...   \n",
       "21          Reward (Mis)design for autonomous driving   \n",
       "22  Planning and acting in partially observable st...   \n",
       "23  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "1                                         Tim Miller    February 2019   \n",
       "2                                  Margaret A. Boden      August 1998   \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "4                     Ilaria Tiddi, Stefan Schlobach     January 2022   \n",
       "5                     Henry Prakken, Giovanni Sartor     October 2015   \n",
       "6    Richard S. Sutton, Doina Precup, Satinder Singh      August 1999   \n",
       "7          Kjersti Aas, Martin Jullum, Anders Løland   September 2021   \n",
       "8                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "9                      Saurabh Arora, Prashant Doshi      August 2021   \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "12  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021   \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "16                        Ron Kohavi, George H. John    December 1997   \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "18   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021   \n",
       "19                            Luigia Carlucci Aiello        June 2016   \n",
       "20            Patrick Lin, Keith Abney, George Bekey       April 2011   \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "23             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "\n",
       "                                            Paper URL  \n",
       "0                                    Reward is enough  \n",
       "1   Explanation in artificial intelligence: Insigh...  \n",
       "2              Creativity and artificial intelligence  \n",
       "3   Conflict-based search for optimal multi-agent ...  \n",
       "4   Knowledge graphs as tools for explainable mach...  \n",
       "5   Law and logic: A review from an argumentation ...  \n",
       "6   Between MDPs and semi-MDPs: A framework for te...  \n",
       "7   Explaining individual predictions when feature...  \n",
       "8       Multiple object tracking: A literature review  \n",
       "9   A survey of inverse reinforcement learning: Ch...  \n",
       "10  Evaluating XAI: A comparison of rule-based and...  \n",
       "11  Explainable AI tools for legal reasoning about...  \n",
       "12            Hard choices in artificial intelligence  \n",
       "13  Assessing the communication gap between AI mod...  \n",
       "14  Explaining black-box classifiers using post-ho...  \n",
       "15  The Hanabi challenge: A new frontier for AI re...  \n",
       "16              Wrappers for feature subset selection  \n",
       "17  Artificial cognition for social human–robot in...  \n",
       "18  A review of possible effects of cognitive bias...  \n",
       "19  The multifaceted impact of Ada Lovelace in the...  \n",
       "20  Robot ethics: Mapping the issues for a mechani...  \n",
       "21          Reward (Mis)design for autonomous driving  \n",
       "22  Planning and acting in partially observable st...  \n",
       "23  What do we want from Explainable Artificial In...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "# days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "# Scrape below mentioned details and make data frame-\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "title = []\n",
    "for i in  soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    title.append(i.text)\n",
    "    \n",
    "    \n",
    "authors = []\n",
    "for i in  soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    authors.append(i.text)\n",
    "    \n",
    "date = []\n",
    "for i in  soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    date.append(i.text)\n",
    "                        \n",
    "link = []\n",
    "for i in  soup.find_all('a',class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    link.append(i.text)\n",
    "    \n",
    "\n",
    "print(len(title),len(authors),len(date),len(link)) \n",
    "\n",
    "df = pd.DataFrame({'Paper Title':title,'Authors':authors,'Published Date':date,'Paper URL':link})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3646e2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 21 21 21 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>ImageURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrendsMalad West, North Western</td>\n",
       "      <td>₹ 700 for 2 (approx) | North Indian, Chinese, ...</td>\n",
       "      <td>Malad West, North Western</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discovery RestaurantJuhu, Andheri West</td>\n",
       "      <td>₹ 900 for 2 (approx) | Chinese, Thai, Asian</td>\n",
       "      <td>Juhu, Andheri West</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Punjabi FusionM.I.D.C, Andheri East</td>\n",
       "      <td>₹ 700 for 2 (approx) | Chinese, North Indian, ...</td>\n",
       "      <td>M.I.D.C, Andheri East</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe BollywoodHigh Street Mall,Thane West, Thane</td>\n",
       "      <td>₹ 400 for 2 (approx) | Fast Food, Chinese</td>\n",
       "      <td>High Street Mall,Thane West, Thane</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MahaBellyThane West, Thane</td>\n",
       "      <td>₹ 500 for 2 (approx) | Chinese, North Indian, ...</td>\n",
       "      <td>Thane West, Thane</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gully GrillShah Royale,Kharghar, Navi Mumbai</td>\n",
       "      <td>₹ 300 for 2 (approx) | Pizza, Chinese, Fast Food</td>\n",
       "      <td>Shah Royale,Kharghar, Navi Mumbai</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Uttam Da DhabaMarol, Andheri East</td>\n",
       "      <td>₹ 700 for 2 (approx) | North Indian, Chinese</td>\n",
       "      <td>Marol, Andheri East</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mago's KitchenVashi, Navi Mumbai</td>\n",
       "      <td>₹ 600 for 2 (approx) | Chinese, North Indian, ...</td>\n",
       "      <td>Vashi, Navi Mumbai</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dumpling KhangHardik Villa,Bandra West, Bandra</td>\n",
       "      <td>₹ 600 for 2 (approx) | Chinese, Tibetan</td>\n",
       "      <td>Hardik Villa,Bandra West, Bandra</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rioz Sasa ChilloutKharghar, Navi Mumbai</td>\n",
       "      <td>₹ 500 for 2 (approx) | Chinese, South Indian, ...</td>\n",
       "      <td>Kharghar, Navi Mumbai</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Flames Of FlavorsMira Bhayandar, North Western</td>\n",
       "      <td>₹ 600 for 2 (approx) | Chinese, Thai</td>\n",
       "      <td>Mira Bhayandar, North Western</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wok This WayKandivali West, North Western</td>\n",
       "      <td>₹ 500 for 2 (approx) | Chinese, Korean, Health...</td>\n",
       "      <td>Kandivali West, North Western</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sazio LoungeMoraj Palm Paradise,Sanpada, Navi ...</td>\n",
       "      <td>₹ 1,000 for 2 (approx) | Chinese, Continental,...</td>\n",
       "      <td>Moraj Palm Paradise,Sanpada, Navi Mumbai</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Urban ChulhaKalwa, Dombivali</td>\n",
       "      <td>₹ 700 for 2 (approx) | Chinese, North Indian, ...</td>\n",
       "      <td>Kalwa, Dombivali</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Roast &amp; CoastAmrapali Shopping Center,Vasant V...</td>\n",
       "      <td>₹ 700 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Amrapali Shopping Center,Vasant Vihar, Thane</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Turban TadkaKharghar, Navi Mumbai</td>\n",
       "      <td>₹ 800 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Kharghar, Navi Mumbai</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hungrezy KitchenGhansoli, Navi Mumbai</td>\n",
       "      <td>₹ 1,100 for 2 (approx) | Chinese, North Indian...</td>\n",
       "      <td>Ghansoli, Navi Mumbai</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Food MasterVashi, Navi Mumbai</td>\n",
       "      <td>₹ 600 for 2 (approx) | Chinese, Malvani, North...</td>\n",
       "      <td>Vashi, Navi Mumbai</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Oye BellyKamlesh Apartment,Near Andheri East S...</td>\n",
       "      <td>₹ 800 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Kamlesh Apartment,Near Andheri East Station, A...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MoMo KingMira Road, North Western</td>\n",
       "      <td>₹ 700 for 2 (approx) | Chinese, Fast Food</td>\n",
       "      <td>Mira Road, North Western</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The Spoon StoryBhandup West, Central Suburbs</td>\n",
       "      <td>₹ 900 for 2 (approx) | Chinese, North Indian, ...</td>\n",
       "      <td>Bhandup West, Central Suburbs</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Restaurant name  \\\n",
       "0                     TrendsMalad West, North Western   \n",
       "1              Discovery RestaurantJuhu, Andheri West   \n",
       "2                 Punjabi FusionM.I.D.C, Andheri East   \n",
       "3    Cafe BollywoodHigh Street Mall,Thane West, Thane   \n",
       "4                          MahaBellyThane West, Thane   \n",
       "5        Gully GrillShah Royale,Kharghar, Navi Mumbai   \n",
       "6                   Uttam Da DhabaMarol, Andheri East   \n",
       "7                    Mago's KitchenVashi, Navi Mumbai   \n",
       "8      Dumpling KhangHardik Villa,Bandra West, Bandra   \n",
       "9             Rioz Sasa ChilloutKharghar, Navi Mumbai   \n",
       "10     Flames Of FlavorsMira Bhayandar, North Western   \n",
       "11          Wok This WayKandivali West, North Western   \n",
       "12  Sazio LoungeMoraj Palm Paradise,Sanpada, Navi ...   \n",
       "13                       Urban ChulhaKalwa, Dombivali   \n",
       "14  Roast & CoastAmrapali Shopping Center,Vasant V...   \n",
       "15                  Turban TadkaKharghar, Navi Mumbai   \n",
       "16              Hungrezy KitchenGhansoli, Navi Mumbai   \n",
       "17                  The Food MasterVashi, Navi Mumbai   \n",
       "18  Oye BellyKamlesh Apartment,Near Andheri East S...   \n",
       "19                  MoMo KingMira Road, North Western   \n",
       "20       The Spoon StoryBhandup West, Central Suburbs   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0   ₹ 700 for 2 (approx) | North Indian, Chinese, ...   \n",
       "1         ₹ 900 for 2 (approx) | Chinese, Thai, Asian   \n",
       "2   ₹ 700 for 2 (approx) | Chinese, North Indian, ...   \n",
       "3           ₹ 400 for 2 (approx) | Fast Food, Chinese   \n",
       "4   ₹ 500 for 2 (approx) | Chinese, North Indian, ...   \n",
       "5    ₹ 300 for 2 (approx) | Pizza, Chinese, Fast Food   \n",
       "6        ₹ 700 for 2 (approx) | North Indian, Chinese   \n",
       "7   ₹ 600 for 2 (approx) | Chinese, North Indian, ...   \n",
       "8             ₹ 600 for 2 (approx) | Chinese, Tibetan   \n",
       "9   ₹ 500 for 2 (approx) | Chinese, South Indian, ...   \n",
       "10               ₹ 600 for 2 (approx) | Chinese, Thai   \n",
       "11  ₹ 500 for 2 (approx) | Chinese, Korean, Health...   \n",
       "12  ₹ 1,000 for 2 (approx) | Chinese, Continental,...   \n",
       "13  ₹ 700 for 2 (approx) | Chinese, North Indian, ...   \n",
       "14       ₹ 700 for 2 (approx) | Chinese, North Indian   \n",
       "15       ₹ 800 for 2 (approx) | Chinese, North Indian   \n",
       "16  ₹ 1,100 for 2 (approx) | Chinese, North Indian...   \n",
       "17  ₹ 600 for 2 (approx) | Chinese, Malvani, North...   \n",
       "18       ₹ 800 for 2 (approx) | Chinese, North Indian   \n",
       "19          ₹ 700 for 2 (approx) | Chinese, Fast Food   \n",
       "20  ₹ 900 for 2 (approx) | Chinese, North Indian, ...   \n",
       "\n",
       "                                             Location Ratings  \\\n",
       "0                           Malad West, North Western       5   \n",
       "1                                  Juhu, Andheri West       5   \n",
       "2                               M.I.D.C, Andheri East       5   \n",
       "3                  High Street Mall,Thane West, Thane       5   \n",
       "4                                   Thane West, Thane       5   \n",
       "5                   Shah Royale,Kharghar, Navi Mumbai       5   \n",
       "6                                 Marol, Andheri East       5   \n",
       "7                                  Vashi, Navi Mumbai       5   \n",
       "8                    Hardik Villa,Bandra West, Bandra       5   \n",
       "9                               Kharghar, Navi Mumbai       5   \n",
       "10                      Mira Bhayandar, North Western       5   \n",
       "11                      Kandivali West, North Western       5   \n",
       "12           Moraj Palm Paradise,Sanpada, Navi Mumbai       5   \n",
       "13                                   Kalwa, Dombivali       5   \n",
       "14       Amrapali Shopping Center,Vasant Vihar, Thane       5   \n",
       "15                              Kharghar, Navi Mumbai       5   \n",
       "16                              Ghansoli, Navi Mumbai       5   \n",
       "17                                 Vashi, Navi Mumbai       5   \n",
       "18  Kamlesh Apartment,Near Andheri East Station, A...       5   \n",
       "19                           Mira Road, North Western       5   \n",
       "20                      Bhandup West, Central Suburbs       5   \n",
       "\n",
       "                                             ImageURL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a python program to scrape mentioned details from dineout.co.in and make data frame\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "page = requests.get('https://www.dineout.co.in/mumbai-restaurants/chinese-cuisine')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "name = []\n",
    "for i in  soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    name.append(i.text)\n",
    "    \n",
    "    \n",
    "cuisine = []\n",
    "for i in  soup.find_all('div',class_=\"detail-info\"):\n",
    "    cuisine.append(i.text)\n",
    "    \n",
    "location = []\n",
    "for i in  soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "                        \n",
    "ratings = []\n",
    "for i in  soup.find_all('div',class_=\"restnt-rating rating-5\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "image = []\n",
    "for i in  soup.find_all('img',class_=\"no-img\"):\n",
    "    image.append(i['data-src'])\n",
    "    \n",
    "print(len(name),len(cuisine),len(location),len(ratings),len(image)) \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Restaurant name':name,'Cuisine':cuisine,'Location':location,'Ratings':ratings,'ImageURL':image})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963dc45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
